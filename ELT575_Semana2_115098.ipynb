{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Aluno: Gustavo Teixeira, Matricula 115098"
      ],
      "metadata": {
        "id": "n0MHMTSmqVB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.datasets import mnist, cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n"
      ],
      "metadata": {
        "id": "MtjNu5sbqUlM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(trainX, trainY), (testX, testY) = cifar10.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YL-x9M0qXfZ",
        "outputId": "498952a8-334f-4cde-cfe8-320dbde5edd4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo valores dos pixels em float\n",
        "trainX = trainX.astype('float32')\n",
        "testX = testX.astype('float32')\n",
        "\n",
        "# normalização para escala [0-1]\n",
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0\n",
        "\n",
        "# transformando a variável alvo (target) para uma codificação one hot\n",
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY)"
      ],
      "metadata": {
        "id": "uuaDgPcQqY1w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "s9F45Q82qalG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Configurar o encerramento do treinamento quando o val_loss nao melhora\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "\n",
        "callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "kI3VxFBzqbtP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "histories = []\n",
        "\n",
        "# definindo a validação k-fold\n",
        "kfold = KFold(5, shuffle=True, random_state=1)\n",
        "\n",
        "# loop para as k-folds (cada fold usa subconjuntos de treino e teste diferentes)\n",
        "for train_ix, test_ix in kfold.split(trainX):\n",
        "\n",
        "    model = define_model()\n",
        "\n",
        "    # recorta dados de acordo com índices da k-fold\n",
        "    train_data, train_target, val_data, val_target = trainX[train_ix], trainY[train_ix], trainX[test_ix], trainY[test_ix]\n",
        "\n",
        "    # treinamento do modelo\n",
        "    history = model.fit(train_data, train_target,\n",
        "                        epochs=10, batch_size=32,\n",
        "                        validation_data=(val_data, val_target),\n",
        "                        verbose=1)\n",
        "\n",
        "    # desempenho do modelo\n",
        "    _, acc = model.evaluate(val_data, val_target, verbose=0)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "\n",
        "    # armazena resultados de cada modelo treinado dentro da k-fold\n",
        "    scores.append(acc)\n",
        "    histories.append(history)\n",
        "\n",
        "print('Acurácia: média=%.3f desvio=%.3f' % (np.mean(scores)*100, np.std(scores)*100))\n",
        "plt.boxplot(scores)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LCXcVBdNqcXQ",
        "outputId": "68b45d9a-c3e0-4d31-960c-4c3dbfbbb21a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 18s 5ms/step - loss: 1.3779 - accuracy: 0.5179 - val_loss: 1.2355 - val_accuracy: 0.5571\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 1.0080 - accuracy: 0.6483 - val_loss: 1.1592 - val_accuracy: 0.5926\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.8122 - accuracy: 0.7147 - val_loss: 1.1490 - val_accuracy: 0.6153\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.6341 - accuracy: 0.7790 - val_loss: 1.3516 - val_accuracy: 0.6007\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.4850 - accuracy: 0.8323 - val_loss: 1.4665 - val_accuracy: 0.6105\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3594 - accuracy: 0.8740 - val_loss: 1.5212 - val_accuracy: 0.6128\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2688 - accuracy: 0.9063 - val_loss: 1.9954 - val_accuracy: 0.5921\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2123 - accuracy: 0.9268 - val_loss: 2.0661 - val_accuracy: 0.5933\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1733 - accuracy: 0.9407 - val_loss: 2.3496 - val_accuracy: 0.5797\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1517 - accuracy: 0.9481 - val_loss: 2.6174 - val_accuracy: 0.5769\n",
            "> 57.690\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 9s 5ms/step - loss: 1.3762 - accuracy: 0.5161 - val_loss: 1.1801 - val_accuracy: 0.5871\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9923 - accuracy: 0.6504 - val_loss: 1.1586 - val_accuracy: 0.6036\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.7808 - accuracy: 0.7267 - val_loss: 1.1834 - val_accuracy: 0.6191\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.5874 - accuracy: 0.7946 - val_loss: 1.4209 - val_accuracy: 0.5849\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4488 - accuracy: 0.8424 - val_loss: 1.4345 - val_accuracy: 0.5986\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3078 - accuracy: 0.8915 - val_loss: 1.6703 - val_accuracy: 0.6139\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2241 - accuracy: 0.9224 - val_loss: 2.2844 - val_accuracy: 0.5853\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1939 - accuracy: 0.9342 - val_loss: 2.3458 - val_accuracy: 0.5943\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1619 - accuracy: 0.9449 - val_loss: 2.4007 - val_accuracy: 0.5874\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.1377 - accuracy: 0.9532 - val_loss: 2.4457 - val_accuracy: 0.6088\n",
            "> 60.880\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 8s 4ms/step - loss: 1.3815 - accuracy: 0.5138 - val_loss: 1.3556 - val_accuracy: 0.5204\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 1.0261 - accuracy: 0.6395 - val_loss: 1.1845 - val_accuracy: 0.5980\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8290 - accuracy: 0.7092 - val_loss: 1.1674 - val_accuracy: 0.6125\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.6463 - accuracy: 0.7743 - val_loss: 1.6935 - val_accuracy: 0.5275\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4947 - accuracy: 0.8255 - val_loss: 1.4513 - val_accuracy: 0.6007\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3702 - accuracy: 0.8723 - val_loss: 1.7978 - val_accuracy: 0.5894\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2850 - accuracy: 0.9006 - val_loss: 2.0331 - val_accuracy: 0.5794\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2271 - accuracy: 0.9205 - val_loss: 2.2431 - val_accuracy: 0.5933\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1843 - accuracy: 0.9382 - val_loss: 2.3421 - val_accuracy: 0.5811\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1653 - accuracy: 0.9445 - val_loss: 3.0597 - val_accuracy: 0.5661\n",
            "> 56.610\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 8s 5ms/step - loss: 1.4035 - accuracy: 0.5072 - val_loss: 1.2204 - val_accuracy: 0.5715\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0206 - accuracy: 0.6385 - val_loss: 1.2825 - val_accuracy: 0.5693\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.7995 - accuracy: 0.7192 - val_loss: 1.2764 - val_accuracy: 0.5618\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.6188 - accuracy: 0.7857 - val_loss: 1.5714 - val_accuracy: 0.5571\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4557 - accuracy: 0.8390 - val_loss: 1.9465 - val_accuracy: 0.5567\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.3447 - accuracy: 0.8806 - val_loss: 1.6399 - val_accuracy: 0.6069\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2546 - accuracy: 0.9134 - val_loss: 1.9363 - val_accuracy: 0.5918\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.2083 - accuracy: 0.9290 - val_loss: 2.0137 - val_accuracy: 0.5896\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.1597 - accuracy: 0.9450 - val_loss: 2.3427 - val_accuracy: 0.5986\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1453 - accuracy: 0.9498 - val_loss: 2.6831 - val_accuracy: 0.5947\n",
            "> 59.470\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 8s 5ms/step - loss: 1.3653 - accuracy: 0.5199 - val_loss: 1.3366 - val_accuracy: 0.5189\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.0040 - accuracy: 0.6449 - val_loss: 1.2516 - val_accuracy: 0.5592\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.7835 - accuracy: 0.7236 - val_loss: 1.2085 - val_accuracy: 0.6095\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5971 - accuracy: 0.7927 - val_loss: 1.2335 - val_accuracy: 0.6187\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4330 - accuracy: 0.8488 - val_loss: 1.5715 - val_accuracy: 0.5871\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.3150 - accuracy: 0.8930 - val_loss: 1.7735 - val_accuracy: 0.6056\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.2435 - accuracy: 0.9168 - val_loss: 2.0692 - val_accuracy: 0.5832\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 4ms/step - loss: 0.1919 - accuracy: 0.9345 - val_loss: 2.3889 - val_accuracy: 0.5557\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.1653 - accuracy: 0.9456 - val_loss: 2.5807 - val_accuracy: 0.5881\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.1371 - accuracy: 0.9541 - val_loss: 2.8822 - val_accuracy: 0.5534\n",
            "> 55.340\n",
            "Acurácia: média=57.998 desvio=1.978\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(model.predict(np.expand_dims(testX[31], axis=0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PozUnPyqg8S",
        "outputId": "c015cad9-ee36-4731-a08a-3c6e789ddd4e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 130ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pergunta: Houve muita diferença no desempenho da rede treinada quando comparado ao exemplo?\n",
        "\n",
        "Acurácia: média=57.998 desvio=1.978\n",
        "\n",
        "\n",
        "Sim, houve bastante diferenca. Esse modelo apresentou uma acuracia muito baixa para o dataset cifar10"
      ],
      "metadata": {
        "id": "ROd3DLjcs9fX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Realizando alteracao sugerida:\n",
        "Adicionado mais dois blocos de camadas Conv2D (64 filtros 3x3 - relu) + MaxPooling (2 x 2) antes da camada Flatten e compare os resultados"
      ],
      "metadata": {
        "id": "iO3jIkoGtuWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_new_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "z_loOF0GtIsV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinando novamente com a alteracao sugerida\n"
      ],
      "metadata": {
        "id": "FP1BLwostfVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "histories = []\n",
        "\n",
        "# definindo a validação k-fold\n",
        "kfold = KFold(5, shuffle=True, random_state=1)\n",
        "\n",
        "# loop para as k-folds (cada fold usa subconjuntos de treino e teste diferentes)\n",
        "for train_ix, test_ix in kfold.split(trainX):\n",
        "\n",
        "    model = define_new_model()\n",
        "\n",
        "    # recorta dados de acordo com índices da k-fold\n",
        "    train_data, train_target, val_data, val_target = trainX[train_ix], trainY[train_ix], trainX[test_ix], trainY[test_ix]\n",
        "\n",
        "    # treinamento do modelo\n",
        "    history = model.fit(train_data, train_target,\n",
        "                        epochs=10, batch_size=32,\n",
        "                        validation_data=(val_data, val_target),\n",
        "                        verbose=1)\n",
        "\n",
        "    # desempenho do modelo\n",
        "    _, acc = model.evaluate(val_data, val_target, verbose=0)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "\n",
        "    # armazena resultados de cada modelo treinado dentro da k-fold\n",
        "    scores.append(acc)\n",
        "    histories.append(history)\n",
        "\n",
        "print('Acurácia: média=%.3f desvio=%.3f' % (np.mean(scores)*100, np.std(scores)*100))\n",
        "plt.boxplot(scores)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0pDkUbUethl_",
        "outputId": "51dbf506-c619-4866-e8f0-3f8b46ab27bc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 10s 7ms/step - loss: 1.3316 - accuracy: 0.5254 - val_loss: 1.4548 - val_accuracy: 0.4840\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9997 - accuracy: 0.6503 - val_loss: 1.0887 - val_accuracy: 0.6186\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8537 - accuracy: 0.6999 - val_loss: 1.0650 - val_accuracy: 0.6343\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7502 - accuracy: 0.7390 - val_loss: 1.0640 - val_accuracy: 0.6426\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6613 - accuracy: 0.7710 - val_loss: 1.0193 - val_accuracy: 0.6604\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5746 - accuracy: 0.8000 - val_loss: 1.5507 - val_accuracy: 0.5807\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.5047 - accuracy: 0.8217 - val_loss: 1.0814 - val_accuracy: 0.6697\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4325 - accuracy: 0.8479 - val_loss: 1.1146 - val_accuracy: 0.6804\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3814 - accuracy: 0.8655 - val_loss: 1.1374 - val_accuracy: 0.6703\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3258 - accuracy: 0.8844 - val_loss: 1.3475 - val_accuracy: 0.6638\n",
            "> 66.380\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 9s 5ms/step - loss: 1.3074 - accuracy: 0.5345 - val_loss: 1.1237 - val_accuracy: 0.6076\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.9775 - accuracy: 0.6582 - val_loss: 1.2091 - val_accuracy: 0.5924\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8342 - accuracy: 0.7093 - val_loss: 0.9580 - val_accuracy: 0.6707\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7261 - accuracy: 0.7463 - val_loss: 1.0418 - val_accuracy: 0.6694\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6366 - accuracy: 0.7771 - val_loss: 1.0884 - val_accuracy: 0.6514\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5561 - accuracy: 0.8048 - val_loss: 1.1707 - val_accuracy: 0.6519\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4786 - accuracy: 0.8328 - val_loss: 1.1002 - val_accuracy: 0.6751\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.4175 - accuracy: 0.8531 - val_loss: 1.1978 - val_accuracy: 0.6814\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3527 - accuracy: 0.8741 - val_loss: 1.2431 - val_accuracy: 0.6753\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.3052 - accuracy: 0.8917 - val_loss: 1.6334 - val_accuracy: 0.6147\n",
            "> 61.470\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 9s 6ms/step - loss: 1.3081 - accuracy: 0.5347 - val_loss: 1.6237 - val_accuracy: 0.4940\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9677 - accuracy: 0.6615 - val_loss: 1.2150 - val_accuracy: 0.5908\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8281 - accuracy: 0.7117 - val_loss: 1.0965 - val_accuracy: 0.6264\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7288 - accuracy: 0.7461 - val_loss: 1.0534 - val_accuracy: 0.6490\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6397 - accuracy: 0.7765 - val_loss: 2.4034 - val_accuracy: 0.3330\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.5690 - accuracy: 0.8013 - val_loss: 1.2355 - val_accuracy: 0.6067\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4927 - accuracy: 0.8256 - val_loss: 1.0670 - val_accuracy: 0.6815\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4334 - accuracy: 0.8454 - val_loss: 1.1436 - val_accuracy: 0.6709\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3730 - accuracy: 0.8683 - val_loss: 1.1976 - val_accuracy: 0.6716\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3288 - accuracy: 0.8836 - val_loss: 1.3925 - val_accuracy: 0.6582\n",
            "> 65.820\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 9s 5ms/step - loss: 1.3307 - accuracy: 0.5259 - val_loss: 1.2221 - val_accuracy: 0.5810\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.9757 - accuracy: 0.6601 - val_loss: 1.0398 - val_accuracy: 0.6383\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8351 - accuracy: 0.7075 - val_loss: 1.0283 - val_accuracy: 0.6541\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7233 - accuracy: 0.7469 - val_loss: 1.2155 - val_accuracy: 0.6120\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.6318 - accuracy: 0.7777 - val_loss: 1.0948 - val_accuracy: 0.6613\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.5601 - accuracy: 0.8047 - val_loss: 1.0499 - val_accuracy: 0.6719\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4886 - accuracy: 0.8280 - val_loss: 1.0981 - val_accuracy: 0.6742\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4295 - accuracy: 0.8492 - val_loss: 1.1240 - val_accuracy: 0.6744\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3698 - accuracy: 0.8679 - val_loss: 1.1767 - val_accuracy: 0.6904\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.3306 - accuracy: 0.8819 - val_loss: 1.2825 - val_accuracy: 0.6781\n",
            "> 67.810\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 9s 5ms/step - loss: 1.3176 - accuracy: 0.5309 - val_loss: 1.4026 - val_accuracy: 0.5237\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9901 - accuracy: 0.6522 - val_loss: 0.9942 - val_accuracy: 0.6499\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8354 - accuracy: 0.7070 - val_loss: 1.1286 - val_accuracy: 0.6200\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7299 - accuracy: 0.7459 - val_loss: 0.9827 - val_accuracy: 0.6784\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.6394 - accuracy: 0.7772 - val_loss: 1.1003 - val_accuracy: 0.6441\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.5626 - accuracy: 0.8042 - val_loss: 1.0224 - val_accuracy: 0.6781\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.4867 - accuracy: 0.8293 - val_loss: 1.2731 - val_accuracy: 0.6427\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.4246 - accuracy: 0.8509 - val_loss: 1.2481 - val_accuracy: 0.6433\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3667 - accuracy: 0.8716 - val_loss: 1.2158 - val_accuracy: 0.6818\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.3152 - accuracy: 0.8890 - val_loss: 1.2839 - val_accuracy: 0.6658\n",
            "> 66.580\n",
            "Acurácia: média=65.612 desvio=2.171\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAj40lEQVR4nO3db2yV9f3/8Vd76DmwSYsOz+FQzywLdFZLQSue1I5NsnaEbWbMabqtC9gtZKtnWKlb4IwBuuCpC0K6COFII6wJGlk6IIRWmlkzYbEOB3ORrPTQYSlTToV17cHO9fg9V383Fg45Pwr28O98eng+knODq5/r6vvyznl6netczRgeHh4WAACAwTJTPQAAAMCnIVgAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGG9cqge4WizL0gcffKCJEycqIyMj1eMAAIBRGB4e1tmzZzV16lRlZl78OkraBMsHH3wgj8eT6jEAAMBlOHnypG677baL/jxtgmXixImS/nfC2dnZKZ4GAACMRiQSkcfjib+PX8xlBcumTZu0bt06hcNhzZo1S88//7zuu+++i67v7+/XypUrtXPnTvX19en2229XfX29vv71r0uSYrGYnnrqKW3fvl3hcFhTp07Vo48+ql/+8pej/njn3Lrs7GyCBQCAMebT3u+TDpYdO3aotrZWwWBQXq9X9fX1mj9/vjo7O+V0Oi9YH41GVV5eLqfTqaamJuXm5urEiROaNGlSfM2vf/1rbd68WY2Njbrrrrv0l7/8RVVVVcrJydHjjz+e7IgAACDNZCT715q9Xq/mzJmjjRs3Svrfza4ej0dLly7VihUrLlgfDAa1bt06HT16VFlZWSMe85vf/KZcLpdefPHF+LbvfOc7mjBhgrZv3z6quSKRiHJycjQwMMAVFgAAxojRvn8n9bXmaDSqQ4cOqays7PwBMjNVVlam9vb2EffZs2ePSkpK5PP55HK5VFhYqEAgoFgsFl9z//33q62tTaFQSJL0t7/9TX/605+0YMGCi84yNDSkSCSS8AIAAOkpqY+Ezpw5o1gsJpfLlbDd5XLp6NGjI+5z/Phxvf7666qsrFRLS4u6urr02GOP6ZNPPtGaNWskSStWrFAkEtEdd9whm82mWCymZ555RpWVlRedpa6uTk8//XQy4wMAgDHqmj84zrIsOZ1ObdmyRcXFxaqoqNDKlSsVDAbja373u9/ppZde0ssvv6zDhw+rsbFRzz33nBobGy96XL/fr4GBgfjr5MmT1/pUAABAiiR1hWXy5Mmy2Wzq7e1N2N7b26spU6aMuI/b7VZWVpZsNlt8W0FBgcLhsKLRqOx2u37+859rxYoV+u53vytJmjlzpk6cOKG6ujotXrx4xOM6HA45HI5kxgcAAGNUUldY7Ha7iouL1dbWFt9mWZba2tpUUlIy4j6lpaXq6uqSZVnxbaFQSG63W3a7XZL0n//854Kn29lstoR9AADAjSvpj4Rqa2vV0NCgxsZGdXR0qLq6WoODg6qqqpIkLVq0SH6/P76+urpafX19qqmpUSgUUnNzswKBgHw+X3zNgw8+qGeeeUbNzc3q7u7Wrl27tGHDBn3729++CqcIAADGuqSfw1JRUaHTp09r9erVCofDmj17tvbt2xe/EbenpyfhaonH41Fra6uWLVumoqIi5ebmqqamRsuXL4+vef7557Vq1So99thj+vDDDzV16lT9+Mc/1urVq6/CKQIYy2KxmA4cOKBTp07J7XZr7ty5CR8xA7gxJP0cFlPxHBYg/ezcuVNPPvmkuru749vy8vK0fv16PfTQQ6kbDMBVc02ewwIA18vOnTv18MMPa+bMmWpvb9fZs2fV3t6umTNn6uGHH9bOnTtTPSKA64grLACME4vFNH36dM2cOVO7d+9O+JjZsiwtXLhQR44c0bFjx/h4CBjjuMICYMw6cOCAuru79Ytf/OKCbxBmZmbK7/frvffe04EDB1I0IYDrjWABYJxTp05JkgoLC0f8+bnt59YBSH8ECwDjuN1uSdKRI0dG/Pm57efWAUh/BAsA48ydO1d5eXkKBAIXPEDSsizV1dVp2rRpmjt3boomBHC9ESwAjGOz2bR+/Xrt3btXCxcuTPiW0MKFC7V3714999xz3HAL3ECSfnAcAFwPDz30kJqamvTkk0/q/vvvj2+fNm2ampqaeA4LcIPha80AjMaTboH0Ntr3b66wADCazWbTAw88kOoxAKQY97AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjHdZwbJp0ybl5eVp/Pjx8nq9Onjw4CXX9/f3y+fzye12y+FwKD8/Xy0tLfGf5+XlKSMj44KXz+e7nPEAAECaGZfsDjt27FBtba2CwaC8Xq/q6+s1f/58dXZ2yul0XrA+Go2qvLxcTqdTTU1Nys3N1YkTJzRp0qT4mrfffluxWCz+7yNHjqi8vFyPPPLI5Z0VAABIKxnDw8PDyezg9Xo1Z84cbdy4UZJkWZY8Ho+WLl2qFStWXLA+GAxq3bp1Onr0qLKyskb1O5544gnt3btXx44dU0ZGxqj2iUQiysnJ0cDAgLKzs0d/QgAAIGVG+/6d1EdC0WhUhw4dUllZ2fkDZGaqrKxM7e3tI+6zZ88elZSUyOfzyeVyqbCwUIFAIOGKyv//O7Zv364f/vCHl4yVoaEhRSKRhBcAAEhPSQXLmTNnFIvF5HK5Era7XC6Fw+ER9zl+/LiampoUi8XU0tKiVatWaf369Vq7du2I63fv3q3+/n49+uijl5ylrq5OOTk58ZfH40nmVAAAwBhyzb8lZFmWnE6ntmzZouLiYlVUVGjlypUKBoMjrn/xxRe1YMECTZ069ZLH9fv9GhgYiL9Onjx5LcYHAAAGSOqm28mTJ8tms6m3tzdhe29vr6ZMmTLiPm63W1lZWbLZbPFtBQUFCofDikajstvt8e0nTpzQa6+9pp07d37qLA6HQw6HI5nxAQDAGJXUFRa73a7i4mK1tbXFt1mWpba2NpWUlIy4T2lpqbq6umRZVnxbKBSS2+1OiBVJ2rZtm5xOp77xjW8kMxYAAEhzSX8kVFtbq4aGBjU2Nqqjo0PV1dUaHBxUVVWVJGnRokXy+/3x9dXV1err61NNTY1CoZCam5sVCAQueMaKZVnatm2bFi9erHHjkv62NQAASGNJl0FFRYVOnz6t1atXKxwOa/bs2dq3b1/8Rtyenh5lZp7vII/Ho9bWVi1btkxFRUXKzc1VTU2Nli9fnnDc1157TT09PfrhD394hacEAADSTdLPYTEVz2EBAGDsuSbPYQEAAEgFggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYbl+oBAJjl2LFjOnv27BUf5+OPP1Z3d/eVD3QN5OXlacKECVd8nIkTJ2rGjBlXYSIAn4ZgARB37Ngx5efnp3qMMSUUChEtwHVAsACIO3dlZfv27SooKLiiY6X7FZaOjg794Ac/uCpXowB8OoIFwAUKCgp0zz33XPFxSktLr8I0AMBNtwAAYAwgWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8fhaM4C4jP/7r+6ekqkJ/SHpA/5/5lIm9Id095RMZfzff1M9CnBDIFgAxI3/qEeHf3yTtP/H0v5UT2O2AkmHf3yTOj7qkXR/qscB0h7BAiDuvzd9Xve88JFeeuklFdxxR6rHMVrH0aOqrKzUi1//fKpHAW4IBAuAuOFx4/XXsKWPJ+VLU2enehyjfRy29NewpeFx41M9CnBD4ENqAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgvMsKlk2bNikvL0/jx4+X1+vVwYMHL7m+v79fPp9PbrdbDodD+fn5amlpSVjz/vvv6wc/+IE+97nPacKECZo5c6b+8pe/XM54AAAgzYxLdocdO3aotrZWwWBQXq9X9fX1mj9/vjo7O+V0Oi9YH41GVV5eLqfTqaamJuXm5urEiROaNGlSfM2///1vlZaWat68eXr11Vd166236tixY7r55puv6OQAAEB6SDpYNmzYoCVLlqiqqkqSFAwG1dzcrK1bt2rFihUXrN+6dav6+vr05ptvKisrS5KUl5eXsObXv/61PB6Ptm3bFt82bdq0ZEcDAABpKqmPhKLRqA4dOqSysrLzB8jMVFlZmdrb20fcZ8+ePSopKZHP55PL5VJhYaECgYBisVjCmnvvvVePPPKInE6n7r77bjU0NFxylqGhIUUikYQXAABIT0kFy5kzZxSLxeRyuRK2u1wuhcPhEfc5fvy4mpqaFIvF1NLSolWrVmn9+vVau3ZtwprNmzdrxowZam1tVXV1tR5//HE1NjZedJa6ujrl5OTEXx6PJ5lTAQAAY0jSHwkly7IsOZ1ObdmyRTabTcXFxXr//fe1bt06rVmzJr7m3nvvVSAQkCTdfffdOnLkiILBoBYvXjzicf1+v2pra+P/jkQiRAsAAGkqqWCZPHmybDabent7E7b39vZqypQpI+7jdruVlZUlm80W31ZQUKBwOKxoNCq73S63260777wzYb+CggL9/ve/v+gsDodDDocjmfEBAMAYldRHQna7XcXFxWpra4tvsyxLbW1tKikpGXGf0tJSdXV1ybKs+LZQKCS32y273R5f09nZmbBfKBTS7bffnsx4AAAgTSX9HJba2lo1NDSosbFRHR0dqq6u1uDgYPxbQ4sWLZLf74+vr66uVl9fn2pqahQKhdTc3KxAICCfzxdfs2zZMr311lsKBALq6urSyy+/rC1btiSsAQAAN66k72GpqKjQ6dOntXr1aoXDYc2ePVv79u2L34jb09OjzMzzHeTxeNTa2qply5apqKhIubm5qqmp0fLly+Nr5syZo127dsnv9+tXv/qVpk2bpvr6elVWVl6FUwQAAGNdxvDw8HCqh7gaIpGIcnJyNDAwoOzs7FSPA4xJhw8fVnFxsQ4dOqR77rkn1eMYjf9WwNUx2vdv/pYQAAAwHsECAACMd82fwwJg7PjPf/4j6X8fd1ypjz/+WN3d3Vd8nGshLy9PEyZMuKJjdHR0XKVpAIwGwQIg7ujRo5KkJUuWpHiSsWPixImpHgG4IRAsAOIWLlwoSbrjjjv0mc985oqOle5XWKT/xcqMGTOuwkQAPg3fEgIAACnDt4QAAEDaIFgAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAY77KCZdOmTcrLy9P48ePl9Xp18ODBS67v7++Xz+eT2+2Ww+FQfn6+Wlpa4j9/6qmnlJGRkfC64447Lmc0AACQhsYlu8OOHTtUW1urYDAor9er+vp6zZ8/X52dnXI6nResj0ajKi8vl9PpVFNTk3Jzc3XixAlNmjQpYd1dd92l11577fxg45IeDQAApKmkq2DDhg1asmSJqqqqJEnBYFDNzc3aunWrVqxYccH6rVu3qq+vT2+++aaysrIkSXl5eRcOMm6cpkyZkuw4AADgBpDUR0LRaFSHDh1SWVnZ+QNkZqqsrEzt7e0j7rNnzx6VlJTI5/PJ5XKpsLBQgUBAsVgsYd2xY8c0depUfeELX1BlZaV6enouOcvQ0JAikUjCCwAApKekguXMmTOKxWJyuVwJ210ul8Lh8Ij7HD9+XE1NTYrFYmppadGqVau0fv16rV27Nr7G6/Xqt7/9rfbt26fNmzfrvffe09y5c3X27NmLzlJXV6ecnJz4y+PxJHMqAABgDLnmN4pYliWn06ktW7bIZrOpuLhY77//vtatW6c1a9ZIkhYsWBBfX1RUJK/Xq9tvv12/+93v9KMf/WjE4/r9ftXW1sb/HYlEiBYAANJUUsEyefJk2Ww29fb2Jmzv7e296P0nbrdbWVlZstls8W0FBQUKh8OKRqOy2+0X7DNp0iTl5+erq6vrorM4HA45HI5kxgcAAGNUUh8J2e12FRcXq62tLb7Nsiy1tbWppKRkxH1KS0vV1dUly7Li20KhkNxu94ixIkkfffSR/vGPf8jtdiczHgAASFNJP4eltrZWDQ0NamxsVEdHh6qrqzU4OBj/1tCiRYvk9/vj66urq9XX16eamhqFQiE1NzcrEAjI5/PF1/zsZz/TG2+8oe7ubr355pv69re/LZvNpu9973tX4RQBAMBYl/Q9LBUVFTp9+rRWr16tcDis2bNna9++ffEbcXt6epSZeb6DPB6PWltbtWzZMhUVFSk3N1c1NTVavnx5fM0///lPfe9739O//vUv3XrrrfrSl76kt956S7feeutVOEUAADDWZQwPDw+neoirIRKJKCcnRwMDA8rOzk71OAAAYBRG+/7N3xICAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPYAEAAMYjWAAAgPEuK1g2bdqkvLw8jR8/Xl6vVwcPHrzk+v7+fvl8PrndbjkcDuXn56ulpWXEtc8++6wyMjL0xBNPXM5oAAAgDY1LdocdO3aotrZWwWBQXq9X9fX1mj9/vjo7O+V0Oi9YH41GVV5eLqfTqaamJuXm5urEiROaNGnSBWvffvttvfDCCyoqKrqskwEAAOkp6SssGzZs0JIlS1RVVaU777xTwWBQn/nMZ7R169YR12/dulV9fX3avXu3SktLlZeXp6985SuaNWtWwrqPPvpIlZWVamho0M0333x5ZwMAANJSUsESjUZ16NAhlZWVnT9AZqbKysrU3t4+4j579uxRSUmJfD6fXC6XCgsLFQgEFIvFEtb5fD594xvfSDj2pQwNDSkSiSS8AABAekrqI6EzZ84oFovJ5XIlbHe5XDp69OiI+xw/flyvv/66Kisr1dLSoq6uLj322GP65JNPtGbNGknSK6+8osOHD+vtt98e9Sx1dXV6+umnkxkfAACMUdf8W0KWZcnpdGrLli0qLi5WRUWFVq5cqWAwKEk6efKkampq9NJLL2n8+PGjPq7f79fAwED8dfLkyWt1CgAAIMWSusIyefJk2Ww29fb2Jmzv7e3VlClTRtzH7XYrKytLNpstvq2goEDhcDj+EdOHH36oe+65J/7zWCym/fv3a+PGjRoaGkrY9xyHwyGHw5HM+AAAYIxK6gqL3W5XcXGx2tra4tssy1JbW5tKSkpG3Ke0tFRdXV2yLCu+LRQKye12y26366tf/areffddvfPOO/HXvffeq8rKSr3zzjsjxgoAALixJP215traWi1evFj33nuv7rvvPtXX12twcFBVVVWSpEWLFik3N1d1dXWSpOrqam3cuFE1NTVaunSpjh07pkAgoMcff1ySNHHiRBUWFib8js9+9rP63Oc+d8F2AABwY0o6WCoqKnT69GmtXr1a4XBYs2fP1r59++I34vb09Cgz8/yFG4/Ho9bWVi1btkxFRUXKzc1VTU2Nli9ffvXOAgAApLWM4eHh4VQPcTVEIhHl5ORoYGBA2dnZqR4HAACMwmjfv/lbQgAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAw3mUFy6ZNm5SXl6fx48fL6/Xq4MGDl1zf398vn88nt9sth8Oh/Px8tbS0xH++efNmFRUVKTs7W9nZ2SopKdGrr756OaMBAIA0NC7ZHXbs2KHa2loFg0F5vV7V19dr/vz56uzslNPpvGB9NBpVeXm5nE6nmpqalJubqxMnTmjSpEnxNbfddpueffZZzZgxQ8PDw2psbNS3vvUt/fWvf9Vdd911RScIAADGvozh4eHhZHbwer2aM2eONm7cKEmyLEsej0dLly7VihUrLlgfDAa1bt06HT16VFlZWaP+PbfccovWrVunH/3oR6NaH4lElJOTo4GBAWVnZ4/69wAAgNQZ7ft3Uh8JRaNRHTp0SGVlZecPkJmpsrIytbe3j7jPnj17VFJSIp/PJ5fLpcLCQgUCAcVisRHXx2IxvfLKKxocHFRJSclFZxkaGlIkEkl4AQCA9JRUsJw5c0axWEwulythu8vlUjgcHnGf48ePq6mpSbFYTC0tLVq1apXWr1+vtWvXJqx79913ddNNN8nhcOgnP/mJdu3apTvvvPOis9TV1SknJyf+8ng8yZwKAAAYQ675t4Qsy5LT6dSWLVtUXFysiooKrVy5UsFgMGHdF7/4Rb3zzjv685//rOrqai1evFh///vfL3pcv9+vgYGB+OvkyZPX+lQAAECKJHXT7eTJk2Wz2dTb25uwvbe3V1OmTBlxH7fbraysLNlstvi2goIChcNhRaNR2e12SZLdbtf06dMlScXFxXr77bf1m9/8Ri+88MKIx3U4HHI4HMmMDwAAxqikrrDY7XYVFxerra0tvs2yLLW1tV30fpPS0lJ1dXXJsqz4tlAoJLfbHY+VkViWpaGhoWTGAwAAaSrpj4Rqa2vV0NCgxsZGdXR0qLq6WoODg6qqqpIkLVq0SH6/P76+urpafX19qqmpUSgUUnNzswKBgHw+X3yN3+/X/v371d3drXfffVd+v19//OMfVVlZeRVOEQAAjHVJP4eloqJCp0+f1urVqxUOhzV79mzt27cvfiNuT0+PMjPPd5DH41Fra6uWLVumoqIi5ebmqqamRsuXL4+v+fDDD7Vo0SKdOnVKOTk5KioqUmtrq8rLy6/CKQIAgLEu6eewmIrnsAAAMPZck+ewAAAApALBAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMd1nBsmnTJuXl5Wn8+PHyer06ePDgJdf39/fL5/PJ7XbL4XAoPz9fLS0t8Z/X1dVpzpw5mjhxopxOpxYuXKjOzs7LGQ0AAKShpINlx44dqq2t1Zo1a3T48GHNmjVL8+fP14cffjji+mg0qvLycnV3d6upqUmdnZ1qaGhQbm5ufM0bb7whn8+nt956S3/4wx/0ySef6Gtf+5oGBwcv/8wAAEDayBgeHh5OZgev16s5c+Zo48aNkiTLsuTxeLR06VKtWLHigvXBYFDr1q3T0aNHlZWVNarfcfr0aTmdTr3xxhv68pe/PKp9IpGIcnJyNDAwoOzs7NGfEAAASJnRvn8ndYUlGo3q0KFDKisrO3+AzEyVlZWpvb19xH327NmjkpIS+Xw+uVwuFRYWKhAIKBaLXfT3DAwMSJJuueWWi64ZGhpSJBJJeAEAgPSUVLCcOXNGsVhMLpcrYbvL5VI4HB5xn+PHj6upqUmxWEwtLS1atWqV1q9fr7Vr14643rIsPfHEEyotLVVhYeFFZ6mrq1NOTk785fF4kjkVAAAwhlzzbwlZliWn06ktW7aouLhYFRUVWrlypYLB4IjrfT6fjhw5oldeeeWSx/X7/RoYGIi/Tp48eS3GBwAABhiXzOLJkyfLZrOpt7c3YXtvb6+mTJky4j5ut1tZWVmy2WzxbQUFBQqHw4pGo7Lb7fHtP/3pT7V3717t379ft9122yVncTgccjgcyYwPAADGqKSusNjtdhUXF6utrS2+zbIstbW1qaSkZMR9SktL1dXVJcuy4ttCoZDcbnc8VoaHh/XTn/5Uu3bt0uuvv65p06ZdzrkAAIA0lfRHQrW1tWpoaFBjY6M6OjpUXV2twcFBVVVVSZIWLVokv98fX19dXa2+vj7V1NQoFAqpublZgUBAPp8vvsbn82n79u16+eWXNXHiRIXDYYXDYX388cdX4RQBAMBYl9RHQpJUUVGh06dPa/Xq1QqHw5o9e7b27dsXvxG3p6dHmZnnO8jj8ai1tVXLli1TUVGRcnNzVVNTo+XLl8fXbN68WZL0wAMPJPyubdu26dFHH72M0wIAAOkk6eewmIrnsAAAMPZck+ewAAAApALBAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADAewQIAAIxHsAAAAOMRLAAAwHgECwAAMB7BAgAAjEewAAAA4xEsAADAeONSPQAAXEosFtOBAwd06tQpud1uzZ07VzabLdVjAbjOuMICwFg7d+7U9OnTNW/ePH3/+9/XvHnzNH36dO3cuTPVowG4zggWAEbauXOnHn74Yc2cOVPt7e06e/as2tvbNXPmTD388MNEC3CDyRgeHh5O9RBXQyQSUU5OjgYGBpSdnZ3qcQBcgVgspunTp2vmzJnavXu3MjPP/7+VZVlauHChjhw5omPHjvHxEDDGjfb9myssAIxz4MABdXd36xe/+EVCrEhSZmam/H6/3nvvPR04cCBFEwK43ggWAMY5deqUJKmwsHDEn5/bfm4dgPRHsAAwjtvtliQdOXJkxJ+f235uHYD0R7AAMM7cuXOVl5enQCAgy7ISfmZZlurq6jRt2jTNnTs3RRMCuN4IFgDGsdlsWr9+vfbu3auFCxcmfEto4cKF2rt3r5577jluuAVuIDw4DoCRHnroITU1NenJJ5/U/fffH98+bdo0NTU16aGHHkrhdACuN77WDMBoPOkWSG+jff/mCgsAo9lsNj3wwAOpHgNAinEPCwAAMB7BAgAAjEewAAAA4xEsAADAeAQLAAAwHsECAACMR7AAAADjESwAAMB4BAsAADBe2jzp9txfGIhEIimeBAAAjNa59+1P+0tBaRMsZ8+elSR5PJ4UTwIAAJJ19uxZ5eTkXPTnafPHDy3L0gcffKCJEycqIyMj1eMAuIoikYg8Ho9OnjzJHzcF0szw8LDOnj2rqVOnKjPz4neqpE2wAEhf/DV2ANx0CwAAjEewAAAA4xEsAIzncDi0Zs0aORyOVI8CIEW4hwUAABiPKywAAMB4BAsAADAewQIAAIxHsAAAAOMRLACMtX//fj344IOaOnWqMjIytHv37lSPBCBFCBYAxhocHNSsWbO0adOmVI8CIMXS5o8fAkg/CxYs0IIFC1I9BgADcIUFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABiPbwkBMNZHH32krq6u+L/fe+89vfPOO7rlllv0+c9/PoWTAbje+GvNAIz1xz/+UfPmzbtg++LFi/Xb3/72+g8EIGUIFgAAYDzuYQEAAMYjWAAAgPEIFgAAYDyCBQAAGI9gAQAAxiNYAACA8QgWAABgPIIFAAAYj2ABAADGI1gAAIDxCBYAAGA8ggUAABjv/wHHyJ0FTykaLQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare os resultados\n",
        "\n",
        "Acurácia: média=65.612 desvio=2.171\n",
        "\n",
        "Ao adicionar as camadas extras de Conv2D e MaxPooling, obteve-se um desempenhor melhor para o dataset cifar10, pois ela foi mais capaz de extrair características complexas das imagens, levando a um desempenho melhor na tarefa de classificação.\n"
      ],
      "metadata": {
        "id": "tbU5fUiKvIjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adicionando Dropout"
      ],
      "metadata": {
        "id": "9cMAXfIMvwXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_new_model_com_dropout():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))  # Adicionando Dropout\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))  # Adicionando Dropout\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "VdYf96wPv0X3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "histories = []\n",
        "\n",
        "# definindo a validação k-fold\n",
        "kfold = KFold(5, shuffle=True, random_state=1)\n",
        "\n",
        "# loop para as k-folds (cada fold usa subconjuntos de treino e teste diferentes)\n",
        "for train_ix, test_ix in kfold.split(trainX):\n",
        "\n",
        "    model = define_new_model_com_dropout()\n",
        "\n",
        "    # recorta dados de acordo com índices da k-fold\n",
        "    train_data, train_target, val_data, val_target = trainX[train_ix], trainY[train_ix], trainX[test_ix], trainY[test_ix]\n",
        "\n",
        "    # treinamento do modelo\n",
        "    history = model.fit(train_data, train_target,\n",
        "                        epochs=10, batch_size=32,\n",
        "                        validation_data=(val_data, val_target),\n",
        "                        verbose=1)\n",
        "\n",
        "    # desempenho do modelo\n",
        "    _, acc = model.evaluate(val_data, val_target, verbose=0)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "\n",
        "    # armazena resultados de cada modelo treinado dentro da k-fold\n",
        "    scores.append(acc)\n",
        "    histories.append(history)\n",
        "\n",
        "print('Acurácia: média=%.3f desvio=%.3f' % (np.mean(scores)*100, np.std(scores)*100))\n",
        "plt.boxplot(scores)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GhVfmO18v22z",
        "outputId": "15564501-e58e-41db-ea97-b5b884783d3f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 9s 5ms/step - loss: 1.4268 - accuracy: 0.4906 - val_loss: 1.2745 - val_accuracy: 0.5566\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1003 - accuracy: 0.6138 - val_loss: 1.0828 - val_accuracy: 0.6194\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9814 - accuracy: 0.6556 - val_loss: 1.0655 - val_accuracy: 0.6287\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9016 - accuracy: 0.6848 - val_loss: 1.0855 - val_accuracy: 0.6155\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 8s 6ms/step - loss: 0.8491 - accuracy: 0.7024 - val_loss: 1.0172 - val_accuracy: 0.6437\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.7999 - accuracy: 0.7165 - val_loss: 0.9229 - val_accuracy: 0.6776\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.7634 - accuracy: 0.7331 - val_loss: 0.9215 - val_accuracy: 0.6846\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7266 - accuracy: 0.7444 - val_loss: 0.8815 - val_accuracy: 0.6953\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6984 - accuracy: 0.7536 - val_loss: 1.0460 - val_accuracy: 0.6619\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6730 - accuracy: 0.7596 - val_loss: 0.8679 - val_accuracy: 0.7040\n",
            "> 70.400\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 9s 6ms/step - loss: 1.4441 - accuracy: 0.4828 - val_loss: 1.3532 - val_accuracy: 0.5322\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 1.1164 - accuracy: 0.6079 - val_loss: 1.0527 - val_accuracy: 0.6259\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.9994 - accuracy: 0.6497 - val_loss: 1.0658 - val_accuracy: 0.6255\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9188 - accuracy: 0.6774 - val_loss: 0.9589 - val_accuracy: 0.6720\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8663 - accuracy: 0.6952 - val_loss: 0.9409 - val_accuracy: 0.6780\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8228 - accuracy: 0.7095 - val_loss: 1.1741 - val_accuracy: 0.5997\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7831 - accuracy: 0.7211 - val_loss: 0.9472 - val_accuracy: 0.6749\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7482 - accuracy: 0.7369 - val_loss: 1.3402 - val_accuracy: 0.6007\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.7140 - accuracy: 0.7468 - val_loss: 0.8400 - val_accuracy: 0.7153\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.6938 - accuracy: 0.7556 - val_loss: 0.8502 - val_accuracy: 0.7123\n",
            "> 71.230\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 9s 6ms/step - loss: 1.4374 - accuracy: 0.4809 - val_loss: 1.3220 - val_accuracy: 0.5325\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1105 - accuracy: 0.6060 - val_loss: 1.1393 - val_accuracy: 0.6035\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.0004 - accuracy: 0.6515 - val_loss: 1.0236 - val_accuracy: 0.6444\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9224 - accuracy: 0.6764 - val_loss: 1.1204 - val_accuracy: 0.6133\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8679 - accuracy: 0.6984 - val_loss: 1.0016 - val_accuracy: 0.6577\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8292 - accuracy: 0.7091 - val_loss: 0.9401 - val_accuracy: 0.6732\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7860 - accuracy: 0.7258 - val_loss: 0.8848 - val_accuracy: 0.6995\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7472 - accuracy: 0.7389 - val_loss: 0.8896 - val_accuracy: 0.6999\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.7294 - accuracy: 0.7434 - val_loss: 0.9283 - val_accuracy: 0.6835\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.7024 - accuracy: 0.7530 - val_loss: 0.9375 - val_accuracy: 0.6837\n",
            "> 68.370\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 9s 6ms/step - loss: 1.4328 - accuracy: 0.4854 - val_loss: 1.3520 - val_accuracy: 0.5262\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1119 - accuracy: 0.6069 - val_loss: 1.0668 - val_accuracy: 0.6241\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 1.0029 - accuracy: 0.6470 - val_loss: 1.1629 - val_accuracy: 0.5975\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9444 - accuracy: 0.6691 - val_loss: 0.9434 - val_accuracy: 0.6716\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8936 - accuracy: 0.6884 - val_loss: 1.0134 - val_accuracy: 0.6467\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.8446 - accuracy: 0.7039 - val_loss: 1.0179 - val_accuracy: 0.6388\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.8099 - accuracy: 0.7186 - val_loss: 1.0464 - val_accuracy: 0.6331\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7768 - accuracy: 0.7284 - val_loss: 0.8951 - val_accuracy: 0.6956\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.7458 - accuracy: 0.7401 - val_loss: 0.8724 - val_accuracy: 0.7006\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7064 - accuracy: 0.7513 - val_loss: 0.9507 - val_accuracy: 0.6876\n",
            "> 68.760\n",
            "Epoch 1/10\n",
            "1250/1250 [==============================] - 9s 5ms/step - loss: 1.4454 - accuracy: 0.4812 - val_loss: 1.2162 - val_accuracy: 0.5641\n",
            "Epoch 2/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 1.1023 - accuracy: 0.6105 - val_loss: 1.3392 - val_accuracy: 0.5557\n",
            "Epoch 3/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9897 - accuracy: 0.6548 - val_loss: 1.1061 - val_accuracy: 0.6169\n",
            "Epoch 4/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.9180 - accuracy: 0.6820 - val_loss: 1.3734 - val_accuracy: 0.5459\n",
            "Epoch 5/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8738 - accuracy: 0.6940 - val_loss: 1.0142 - val_accuracy: 0.6475\n",
            "Epoch 6/10\n",
            "1250/1250 [==============================] - 7s 6ms/step - loss: 0.8339 - accuracy: 0.7086 - val_loss: 1.1213 - val_accuracy: 0.6179\n",
            "Epoch 7/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7995 - accuracy: 0.7208 - val_loss: 1.0406 - val_accuracy: 0.6637\n",
            "Epoch 8/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7718 - accuracy: 0.7318 - val_loss: 0.9500 - val_accuracy: 0.6693\n",
            "Epoch 9/10\n",
            "1250/1250 [==============================] - 7s 5ms/step - loss: 0.7464 - accuracy: 0.7384 - val_loss: 0.8649 - val_accuracy: 0.6975\n",
            "Epoch 10/10\n",
            "1250/1250 [==============================] - 6s 5ms/step - loss: 0.7205 - accuracy: 0.7489 - val_loss: 1.0464 - val_accuracy: 0.6543\n",
            "> 65.430\n",
            "Acurácia: média=68.838 desvio=2.000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comentando os resultados obtidos\n",
        "\n",
        "Acurácia: média=68.838 desvio=2.000\n",
        "\n",
        "\n",
        "Adicionar as camadas de dropout ajudou a melhorar ainda mais (levemente em relacao ao anterior: 65.612) o desempenho do modelo, evitando o overfitting durante o treinamento"
      ],
      "metadata": {
        "id": "MmNIiNbzwLQh"
      }
    }
  ]
}